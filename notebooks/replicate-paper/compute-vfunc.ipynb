{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for parallel evaluation of the value function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# papermill parameter: notebook id\n",
    "aid = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import nshap\n",
    "\n",
    "import paperutil\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "import datasets\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The different compute jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = list(nshap.powerset(list(range(10))))\n",
    "\n",
    "all_jobs = list(subsets)\n",
    "print(len(all_jobs), 'different compute jobs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The current job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = aid\n",
    "dataset = 'folk_travel'\n",
    "classifier = 'knn'\n",
    "i_datapoint = 0\n",
    "random_seed = i_datapoint\n",
    "\n",
    "print(job_id, dataset, classifier, i_datapoint, random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test, feature_names = datasets.load_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_classification = datasets.is_classification(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict, proba or decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'predict'\n",
    "if is_classification:\n",
    "    method = 'proba'\n",
    "if classifier == 'gam':\n",
    "    method = 'decision'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The number of samples is limited by the size of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_samples = 1000000\n",
    "num_samples = min(max_samples, X_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create output dir structure, if it does not already exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "froot = f'../../results/n_shapley_values/{dataset}/{classifier}/observation_{i_datapoint}_{method}_{num_samples}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = ['../../results/', \n",
    "         '../../results/n_shapley_values/'\n",
    "         f'../../results/n_shapley_values/{dataset}/', \n",
    "         f'../../results/n_shapley_values/{dataset}/{classifier}/',\n",
    "         froot]\n",
    "for p in paths:\n",
    "    if not os.path.exists( p ):\n",
    "        os.mkdir( p )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = paperutil.train_classifier(dataset, classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The value function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if method == 'predict':\n",
    "    vfunc = nshap.vfunc.interventional_shap(clf.predict, X_train, num_samples=num_samples, random_state=0)\n",
    "elif method == 'proba':\n",
    "    prediction = int( clf.predict( X_test[i_datapoint, :].reshape((1,-1)) ) )\n",
    "    vfunc = nshap.vfunc.interventional_shap(clf.predict_proba, X_train, num_samples=num_samples, random_state=0, target=prediction)\n",
    "elif method == 'decision':\n",
    "    vfunc = nshap.vfunc.interventional_shap(clf.decision_function, X_train, num_samples=num_samples, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the value function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx in range(10):\n",
    "    S = subsets[10*job_id + idx] # 10 jobs per notebook\n",
    "    if len(S) > 0 and np.max(S) >= X_train.shape[1]:\n",
    "        continue\n",
    "    fname = froot + f'v{S}.txt'   \n",
    "    # evaluate the value function and save the result\n",
    "    if not os.path.exists(fname):\n",
    "        result = vfunc(X_test[i_datapoint, :].reshape((1,-1)), S)\n",
    "        with open(fname, 'w+') as f:\n",
    "            f.write(f'{result}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
